{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 决策树与随机森林"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import collections\n",
    "import random\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score,precision_score,recall_score,confusion_matrix\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Attrition_Flag</th>\n",
       "      <th>Customer_Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Dependent_count</th>\n",
       "      <th>Education_Level</th>\n",
       "      <th>Marital_Status</th>\n",
       "      <th>Income_Category</th>\n",
       "      <th>Card_Category</th>\n",
       "      <th>Months_on_book</th>\n",
       "      <th>...</th>\n",
       "      <th>Months_Inactive_12_mon</th>\n",
       "      <th>Contacts_Count_12_mon</th>\n",
       "      <th>Credit_Limit</th>\n",
       "      <th>Total_Revolving_Bal</th>\n",
       "      <th>Avg_Open_To_Buy</th>\n",
       "      <th>Total_Amt_Chng_Q4_Q1</th>\n",
       "      <th>Total_Trans_Amt</th>\n",
       "      <th>Total_Trans_Ct</th>\n",
       "      <th>Total_Ct_Chng_Q4_Q1</th>\n",
       "      <th>Avg_Utilization_Ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Existing Customer</td>\n",
       "      <td>46</td>\n",
       "      <td>M</td>\n",
       "      <td>2</td>\n",
       "      <td>Uneducated</td>\n",
       "      <td>Single</td>\n",
       "      <td>$60K - $80K</td>\n",
       "      <td>Blue</td>\n",
       "      <td>35</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5131.0</td>\n",
       "      <td>1484</td>\n",
       "      <td>3647.0</td>\n",
       "      <td>0.750</td>\n",
       "      <td>7432</td>\n",
       "      <td>92</td>\n",
       "      <td>0.559</td>\n",
       "      <td>0.289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Existing Customer</td>\n",
       "      <td>58</td>\n",
       "      <td>M</td>\n",
       "      <td>3</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>Married</td>\n",
       "      <td>$120K +</td>\n",
       "      <td>Blue</td>\n",
       "      <td>52</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>17934.0</td>\n",
       "      <td>1578</td>\n",
       "      <td>16356.0</td>\n",
       "      <td>0.593</td>\n",
       "      <td>2005</td>\n",
       "      <td>48</td>\n",
       "      <td>0.778</td>\n",
       "      <td>0.088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Existing Customer</td>\n",
       "      <td>47</td>\n",
       "      <td>M</td>\n",
       "      <td>3</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>$60K - $80K</td>\n",
       "      <td>Blue</td>\n",
       "      <td>36</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>21142.0</td>\n",
       "      <td>0</td>\n",
       "      <td>21142.0</td>\n",
       "      <td>0.812</td>\n",
       "      <td>4360</td>\n",
       "      <td>66</td>\n",
       "      <td>1.357</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Attrited Customer</td>\n",
       "      <td>54</td>\n",
       "      <td>M</td>\n",
       "      <td>2</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>Single</td>\n",
       "      <td>$80K - $120K</td>\n",
       "      <td>Blue</td>\n",
       "      <td>36</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>12342.0</td>\n",
       "      <td>0</td>\n",
       "      <td>12342.0</td>\n",
       "      <td>0.431</td>\n",
       "      <td>1430</td>\n",
       "      <td>37</td>\n",
       "      <td>0.423</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Existing Customer</td>\n",
       "      <td>44</td>\n",
       "      <td>F</td>\n",
       "      <td>3</td>\n",
       "      <td>Uneducated</td>\n",
       "      <td>Single</td>\n",
       "      <td>Less than $40K</td>\n",
       "      <td>Blue</td>\n",
       "      <td>38</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1438.3</td>\n",
       "      <td>0</td>\n",
       "      <td>1438.3</td>\n",
       "      <td>0.801</td>\n",
       "      <td>4287</td>\n",
       "      <td>80</td>\n",
       "      <td>0.667</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id     Attrition_Flag  Customer_Age Gender  Dependent_count  \\\n",
       "0   1  Existing Customer            46      M                2   \n",
       "1   2  Existing Customer            58      M                3   \n",
       "2   3  Existing Customer            47      M                3   \n",
       "3   4  Attrited Customer            54      M                2   \n",
       "4   5  Existing Customer            44      F                3   \n",
       "\n",
       "  Education_Level Marital_Status Income_Category Card_Category  \\\n",
       "0      Uneducated         Single     $60K - $80K          Blue   \n",
       "1        Graduate        Married         $120K +          Blue   \n",
       "2        Graduate        Unknown     $60K - $80K          Blue   \n",
       "3        Graduate         Single    $80K - $120K          Blue   \n",
       "4      Uneducated         Single  Less than $40K          Blue   \n",
       "\n",
       "   Months_on_book  ...  Months_Inactive_12_mon  Contacts_Count_12_mon  \\\n",
       "0              35  ...                       1                      1   \n",
       "1              52  ...                       2                      5   \n",
       "2              36  ...                       3                      2   \n",
       "3              36  ...                       3                      3   \n",
       "4              38  ...                       1                      3   \n",
       "\n",
       "   Credit_Limit  Total_Revolving_Bal  Avg_Open_To_Buy  Total_Amt_Chng_Q4_Q1  \\\n",
       "0        5131.0                 1484           3647.0                 0.750   \n",
       "1       17934.0                 1578          16356.0                 0.593   \n",
       "2       21142.0                    0          21142.0                 0.812   \n",
       "3       12342.0                    0          12342.0                 0.431   \n",
       "4        1438.3                    0           1438.3                 0.801   \n",
       "\n",
       "   Total_Trans_Amt  Total_Trans_Ct  Total_Ct_Chng_Q4_Q1  Avg_Utilization_Ratio  \n",
       "0             7432              92                0.559                  0.289  \n",
       "1             2005              48                0.778                  0.088  \n",
       "2             4360              66                1.357                  0.000  \n",
       "3             1430              37                0.423                  0.000  \n",
       "4             4287              80                0.667                  0.000  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = pd.read_excel(\"data/BankChurners2.xlsx\",sheet_name=0)\n",
    "test_data = pd.read_excel(\"data/BankChurners2.xlsx\",sheet_name=1)\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 决策树"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "    \"\"\"\n",
    "    class Node(self)\n",
    "    |  决策树的每一个节点\n",
    "    |  提供记录节点信息，定位子节点和父节点，存储label等功能\n",
    "    |\n",
    "    |  Atrribute\n",
    "    |  ----------\n",
    "    |  __init__(self) : None\n",
    "    |      初始化函数\n",
    "    |  setLabel(self, label : str) -> None\n",
    "    |      设置节点的label标签\n",
    "    |  add_child_info(self, character : str, label, value) -> None\n",
    "    |      通过传入信息来添加一个子节点\n",
    "    |  add_child_node(self, node, value) -> None\n",
    "    |      通过传入节点来直接添加子节点\n",
    "    |  getLabel(self) -> None\n",
    "    |      获得该节点的label\n",
    "    |  setParent(self, node : 'Node') -> None\n",
    "    |      设置该节点所连接的父节点，在剪枝时需要\n",
    "    \"\"\"\n",
    "    def __init__(self,method : str='ID3') -> None:\n",
    "        if method == 'ID3' or method == 'C4.5':\n",
    "            self.character = None # 储节点类型，存取值['root','child node','leaf']\n",
    "            self.children = {} # 存储子节点的字典，字典的key是连接子节点的edge\n",
    "            self._parent = None # 所连接的父节点\n",
    "            self._label = None # 节点的标签\n",
    "            self.Nt = 0 # 该节点下包含的样本量\n",
    "            self.Ntk = None # 该节点下目标标签的分布，是一个pd.Series\n",
    "            self.entropy = 0 # 该节点下的经验熵\n",
    "            self.depth = None # 该节点所处的树深度\n",
    "            self.maxLabel = None # 该节点下数量最多的目标标签\n",
    "        if method == 'CART':\n",
    "            self.character = None # 储节点类型，存取值['root','child node','leaf']\n",
    "            self.split = None # 划分节点\n",
    "            self.LEFT = None # 左节点\n",
    "            self.RIGHT = None # 右节点\n",
    "            self._parent = None # 所连接的父节点\n",
    "            self._label = None # 节点的标签\n",
    "            self.Nt = 0 # 该节点下包含的样本量\n",
    "            self.Ntk = None # 该节点下目标标签的分布，是一个pd.Series\n",
    "            self.depth = None # 该节点所处的树深度\n",
    "            self.loss = None # 该节点的损失函数值\n",
    "            self.Gini = None # 该节点的Gini指数\n",
    "            self.kind = None # 该节点是类别型还是数值型\n",
    "            self.alpha = None # 决定是否剪枝的临界值\n",
    "\n",
    "    def setLabel(self, label : str) -> None:\n",
    "        \"\"\"\n",
    "        setLabel(self, label : str) -> None\n",
    "            设置节点的label标签\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        label : str\n",
    "            将该节点的标签设置为label\n",
    "        \"\"\"\n",
    "        self._label = label\n",
    "    \n",
    "    def add_child_info(self, character : str, label : str, value) -> None:\n",
    "        \"\"\"\n",
    "        add_child_info(self, character : str, label, value) -> None\n",
    "            通过传入信息来添加一个子节点\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        character : str\n",
    "            子节点的类型，取值['child node','leaf']\n",
    "        label : str\n",
    "            子节点的的标签\n",
    "        value : str, int 或 float\n",
    "            这是父节点与子节点的连接索引\\n\n",
    "            父节点通过self.children[value]来定位到该子节点\n",
    "        \"\"\"\n",
    "        node = Node()\n",
    "        node.character = character\n",
    "        node.setLabel(label)\n",
    "        self.children[value] = node\n",
    "    \n",
    "    def add_child_node(self, node : 'Node', value) -> None:\n",
    "        \"\"\"\n",
    "        add_child_node(self, node, value) -> None\n",
    "            通过传入节点来直接添加子节点\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        node : Node\n",
    "            待添加的子节点子节点\n",
    "        value : str, int 或 float\n",
    "            这是父节点与子节点的连接索引\\n\n",
    "            父节点通过self.children[value]来定位到该子节点\n",
    "        \"\"\"\n",
    "        self.children[value] = node\n",
    "    \n",
    "    def getLabel(self) -> None:\n",
    "        \"\"\"\n",
    "        getLabel(self) -> None\n",
    "            设置节点的label标签\n",
    "        \n",
    "        Return\n",
    "        ----------\n",
    "        self._label : str\n",
    "            返回该节点的标签\n",
    "        \"\"\"\n",
    "        return self._label\n",
    "    \n",
    "    def setParent(self, node : 'Node') -> None:\n",
    "        \"\"\"\n",
    "        setParent(self, node : 'Node') -> None\n",
    "            设置该节点所连接的父节点，在剪枝时需要\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        node : Node\n",
    "            将该节点连接到它的父节点node\n",
    "        \"\"\"\n",
    "        self._parent = node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecisionTree:\n",
    "    \"\"\"\n",
    "    class DecisionTree(task,method):\n",
    "    |  决策树模型\n",
    "    |  利用Node节点生成决策模型，可以指定任务类型是分类或回归，并指定随机数的生成算法\n",
    "    |\n",
    "    |  Parameters\n",
    "    |  ----------\n",
    "    |  task : str, optional\n",
    "    |      决策树的任务，取值['regression','classification']\\n\n",
    "    |      默认值'classification'\n",
    "    |  method : str, optional\n",
    "    |      指定决策树的生成算法\n",
    "    |      当决策树的任务是分类时，默认采用ID3算法，可以指定为C4.5算法\n",
    "    |      当决策树的任务是回归时，采用CART算法\n",
    "    |\n",
    "    |  Atrribute\n",
    "    |  ----------\n",
    "    |  __init__(self, task : str='classification', method : str='ID3') -> None\n",
    "    |      初始化函数\n",
    "    |  fit(self, X, y, is_pruning : bool=True, alpha : float=0.01)\n",
    "    |      训练函数\n",
    "    |  predict(self, X : pd.DataFrame)\n",
    "    |      预测函数\n",
    "    |  accuracy(self, X : pd.DataFrame, y_true : pd.Series) -> float\n",
    "    |      正确率计算函数\n",
    "    |  _TreeGenerator(self, Data : tuple, Attribute : list, deep : int)\n",
    "    |      ID3，C4.5树生成函数\n",
    "    |  _TreeGeneratorCART(self, Data : tuple, Attribute : list, deep : int)\n",
    "    |      CART树生成函数\n",
    "    |  _Pruning(self, alpha : float=0.01) -> None\n",
    "    |      ID3, C4.5剪枝函数\n",
    "    |  _PruningCART(self, valid_data : tuple) -> None\n",
    "    |      CART剪枝函数\n",
    "    \"\"\"\n",
    "    def __init__(self, task : str='classification', method : str='ID3') -> None:\n",
    "        \"\"\"\n",
    "        __init__(self, task : str='classification', method : str='ID3') -> None\n",
    "            初始化函数，设置任务类型和决策树使用的算法\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        task : str, optional\n",
    "            决策树的任务类型，取值['regression','classification']\\n\n",
    "            默认值'classification'\n",
    "        method : str, optional\n",
    "            决策树生成所使用的算法\\n\n",
    "            当决策树的任务是分类时，默认采用ID3算法，可以指定为C4.5算法\\n\n",
    "            当决策树的任务是回归时，采用CART算法\\n\n",
    "        \"\"\"\n",
    "        self.gain = {} # 信息增益\n",
    "        self.task = task\n",
    "        self.method = method\n",
    "        self._columns = None\n",
    "        self._columns_index = {}\n",
    "        # 决策树\n",
    "        self.tree = None\n",
    "        self.Attribute_values = {}\n",
    "        self.leaf_ptr = {}\n",
    "        self.num_leaf = 0\n",
    "        self.treeEntropy = 0\n",
    "        self.N = 0\n",
    "        self.numerical_cols = []\n",
    "        self.category_cols = []\n",
    "        self.alphaTree = {}\n",
    "        self.pruningTree = {}\n",
    "        \n",
    "    def fit(self, X : pd.DataFrame, y : pd.Series, numerical_cols : list, \n",
    "            is_pruning : bool=True, alpha : float=1e-4, valid_data : tuple=None, max_feature_split : int=None, **kwargs) -> None:\n",
    "        \"\"\"\n",
    "        fit(self, X, y, is_pruning : bool=True, alpha : float=0.01) -> None\n",
    "            输入训练数据集，训练函数，生成决策树\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        X : pd.DataFrame\n",
    "            数据的特征\n",
    "        y : pd.Series\n",
    "            数据的标签\n",
    "        is_pruning : bool, optional\n",
    "            是否对训练好的模型进行剪枝，默认值True\n",
    "        valid_data : tuple\n",
    "            对CART决策树剪枝时所需的验证数据集，它应该和训练数据集独立\\n\n",
    "            valid_data的形式为(X_valid,y_valid)的元组\\n\n",
    "        alpha : float, optional\n",
    "            剪枝算法中的正则化系数，默认值1e-4\\n\n",
    "            alpha取值越大，模型复杂度越低\n",
    "        valid_data : tuple\n",
    "            CART决策树在剪枝过程中的验证数据集\\n\n",
    "            valid_data应该具有(X_valid,y_valid)的形式\\n\n",
    "        max_feature_split : int, optional\n",
    "            决策树分裂时所考虑的最大分裂特征数量\\n\n",
    "            默认值为None，表示不限制特征数量，使用所有特征\n",
    "        \"\"\"\n",
    "        # 保存信息\n",
    "        self._columns = list(X.columns)\n",
    "        self.numerical_cols = numerical_cols\n",
    "        self.category_cols = list(set(self._columns) - set(self.numerical_cols))\n",
    "        self.N = X.shape[0]\n",
    "        # 计算信息增量\n",
    "        if self.method == 'ID3' or self.method == 'C4.5':\n",
    "            for i,col in enumerate(self._columns):\n",
    "                self.gain[col] = self.__mutaul_information(X[col],y)\n",
    "                self.Attribute_values[col] = X[col].unique()\n",
    "                self._columns_index[col] = i\n",
    "            self.gain = pd.Series(self.gain)\n",
    "            self.tree = self._TreeGenerator((X,y), self._columns,deep=1)\n",
    "            self.tree.character = 'root node'\n",
    "            self.leaf_ptr = pd.Series(self.leaf_ptr)\n",
    "            self.num_leaf = sum([len(l) for l in self.leaf_ptr])\n",
    "        if self.method == 'CART':\n",
    "            for i,col in enumerate(self._columns):\n",
    "                self._columns_index[col] = i\n",
    "            if max_feature_split:\n",
    "                cols_use = pd.Series(self._columns)\n",
    "                cols_use = list(cols_use.sample(n=max_feature_split).values)\n",
    "            else:\n",
    "                cols_use = self._columns.copy()\n",
    "            self.tree = self._TreeGeneratorCART((X,y), cols_use, deep=1, **kwargs)\n",
    "            self.tree.character = 'root node'\n",
    "            self.leaf_ptr = pd.Series(self.leaf_ptr)\n",
    "            self.num_leaf = sum([len(l) for l in self.leaf_ptr])\n",
    "        # 剪枝\n",
    "        if is_pruning:\n",
    "            if self.method == 'CART':\n",
    "                if not valid_data:\n",
    "                    raise \"没有提供验证数据集!\"\n",
    "                self._PruningCART(valid_data=valid_data)\n",
    "            else:\n",
    "                self._Pruning(alpha)\n",
    "        \n",
    "\n",
    "    def predict(self, X : pd.DataFrame) -> pd.Series:\n",
    "        \"\"\"\n",
    "        predict(self, X : pd.DataFrame) -> pd.Series\n",
    "            输入数据，进行预测\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        X : pd.DataFrame\n",
    "            数据的特征\n",
    "\n",
    "        Return\n",
    "        ----------\n",
    "        y_pred : pd.Series\n",
    "            模型在输入X上的预测\n",
    "        \"\"\"\n",
    "        y_pred = []\n",
    "        for x in X.values:\n",
    "            tree = self.tree\n",
    "            if self.method == 'ID3' or self.method == 'C4.5':\n",
    "                while tree.character != 'leaf':\n",
    "                    tree = tree.children[x[self._columns_index[tree.getLabel()]]]\n",
    "                y_pred.append(tree.getLabel())\n",
    "            if self.method == 'CART':\n",
    "                # try:\n",
    "                while tree.character != 'leaf':\n",
    "                        if tree.kind == 'category':\n",
    "                            if x[self._columns_index[tree.getLabel()]] == tree.split:\n",
    "                                tree = tree.LEFT\n",
    "                            else:\n",
    "                                tree = tree.RIGHT\n",
    "                        if tree.kind == 'numerical':\n",
    "                            if x[self._columns_index[tree.getLabel()]] <= tree.split:\n",
    "                                tree = tree.LEFT\n",
    "                            else:\n",
    "                                tree = tree.RIGHT\n",
    "                y_pred.append(tree.getLabel())\n",
    "                # except:\n",
    "                #     y_pred.append(tree.getLabel())\n",
    "        return pd.Series(y_pred)\n",
    "\n",
    "    def accuracy(self, X : pd.DataFrame, y_true : pd.Series, eval : str='mean square error') -> float:\n",
    "        \"\"\"\n",
    "        accuracy(self, X : pd.DataFrame, y_true : pd.Series) -> float\n",
    "            输入数据，进行预测\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        X : pd.DataFrame\n",
    "            数据的特征\n",
    "        y_true : pd.Series\n",
    "            给定输入X的真实标签\n",
    "        eval : str, optional\n",
    "            回归问题的评估指标，可选['MSE','MAE']\n",
    "            默认值'MSE'\n",
    "        \n",
    "        Return\n",
    "        ----------\n",
    "        acc : float\n",
    "            模型在输入X上预测的准确率\n",
    "        \"\"\"\n",
    "        y_pred = self.predict(X)\n",
    "        if self.task == 'classification':\n",
    "            return (y_pred == y_true).sum() / len(y_true)\n",
    "        if self.task == 'regression':\n",
    "            if eval in ['mean square error','MSE']:\n",
    "                return ((y_pred - y_true)**2).mean()\n",
    "            if eval in ['maximum absolute error','MAE']:\n",
    "                return max(abs(y_pred - y_true))\n",
    "            if eval in ['mean absolute error']:\n",
    "                return (abs(y_pred - y_true)).mean()\n",
    "\n",
    "    def _TreeGenerator(self, Data : tuple, Attribute : list, deep : int) -> None:\n",
    "        \"\"\"\n",
    "        _TreeGenerator(self, Data : tuple, Attribute : list, deep : int) -> None\n",
    "            决策树生成函数\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        Data : tuple\n",
    "            包含特征和标签的元组(X,y)\n",
    "        Attribute : list\n",
    "            特征集合\n",
    "        deep : int\n",
    "            当前递归时树的深度\n",
    "        \"\"\"\n",
    "        # 创建节点，统计该节点下样本分配情况\n",
    "        node = Node()\n",
    "        node.Nt = len(Data[1])\n",
    "        node.Ntk = Data[1].value_counts()\n",
    "        # 统计数量最多的标签\n",
    "        node.maxLabel = Data[1].value_counts().index[0]\n",
    "        # 记录当前树的递归深度\n",
    "        node.depth = deep\n",
    "        # 计算该节点处的熵\n",
    "        if node.Nt > 0:\n",
    "            node.entropy = self.__empiricalEntropy(node.Ntk)\n",
    "        # 若样本全部属于同一类别\n",
    "        if Data[1].nunique() == 1:\n",
    "            node.character = 'leaf'\n",
    "            node.setLabel(Data[1].values[0])\n",
    "            # 保存叶节点的指针，用于剪枝\n",
    "            if deep in self.leaf_ptr:\n",
    "                self.leaf_ptr[deep].append(node) \n",
    "            else:\n",
    "                self.leaf_ptr[deep] = [node]\n",
    "            return node\n",
    "        # 如果A为空集，或者样本在A上的取值完全相同\n",
    "        if len(Attribute) == 0 or max(Data[0][Attribute].nunique()) == 1:\n",
    "            node.character = 'leaf'\n",
    "            node.setLabel((Data[1].value_counts()).index[0])\n",
    "            # 保存叶节点的指针，用于剪枝\n",
    "            if deep in self.leaf_ptr:\n",
    "                self.leaf_ptr[deep].append(node)\n",
    "            else:\n",
    "                self.leaf_ptr[deep] = [node]\n",
    "            return node\n",
    "        # 筛选信息增量最大的属性\n",
    "        Attribute_max = self.gain[Attribute].index[self.gain[Attribute].argmax()]\n",
    "        node.setLabel(Attribute_max)\n",
    "        node.character = 'child node'\n",
    "        for value in self.Attribute_values[Attribute_max]:\n",
    "            index = Data[0][Attribute_max]==value\n",
    "            if index.sum() == 0:\n",
    "                node.add_child_info(character='leaf',label=(Data[1].value_counts()).index[0],value=value)\n",
    "                # 添加父节点关系，更新树深度\n",
    "                node.children[value].setParent(node)\n",
    "                node.children[value].depth = deep + 1\n",
    "            else:\n",
    "                # 更新样本集和标签集，准备递归\n",
    "                Dx = Data[0][index]\n",
    "                Dy = Data[1][index]\n",
    "                Dv = (Dx,Dy)\n",
    "                Attribute_v = Attribute.copy()\n",
    "                Attribute_v.remove(Attribute_max)\n",
    "                # 递归添加叶节点，注意更新深度\n",
    "                node.add_child_node(self._TreeGenerator(Dv,Attribute_v,deep=deep + 1),value=value)\n",
    "                # 添加父节点关系\n",
    "                node.children[value].setParent(node)\n",
    "        return node\n",
    "    \n",
    "    def _TreeGeneratorCART(self, Data : tuple, Attribute : list, deep : int, \\\n",
    "                           sample_threshold : int=10, loss_threshold : float=5, max_depth : int=None) -> None:\n",
    "        \"\"\"\n",
    "        _TreeGeneratorCART(self, Data : tuple, Attribute : list, deep : int) -> None\n",
    "            使用CART算法生成决策树\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        Data : tuple\n",
    "            包含特征和标签的元组(X,y)\n",
    "        Attribute : list\n",
    "            特征集合\n",
    "        deep : int\n",
    "            当前递归时树的深度\n",
    "        sample_threshold : int, optional\n",
    "            样本个数阈值，当划分后样本量小于该阈值\\n\n",
    "            则停止划分，并取均值作为预测值，默认值5\\n\n",
    "        loss_threshold : float, optional\n",
    "            评估指标的临界值，如果是分类任务，则代表Gini指标，如果是回归任务，则代表误差平方和\\n\n",
    "            当划分下所有样本的评价指标小于该阈值时，停止划分\\n\n",
    "            默认值1\\n\n",
    "        \"\"\"\n",
    "        # 创建节点，统计该节点下样本分配情况\n",
    "        node = Node('CART')\n",
    "        node.Nt = len(Data[1])\n",
    "        node.Ntk = Data[1].value_counts()\n",
    "        # 记录当前树的递归深度\n",
    "        node.depth = deep\n",
    "        # 计算该节点处的最优预测及均方损失\n",
    "        if node.Nt > 0:\n",
    "            # 计算均值作为该节点下得最优预测\n",
    "            if self.task == 'regression':\n",
    "                node.maxLabel = Data[1].mean()\n",
    "                node.loss = self.__MSEloss(Data[1],node.maxLabel)\n",
    "            # 以当前类别最多的类得到最优预测\n",
    "            else:\n",
    "                node.maxLabel = (Data[1].value_counts()).index[0]\n",
    "                node.loss = self.__Gini(Data[1])\n",
    "        # 样本量个数小于阈值 OR 如果没有更多特征，即A为空集 OR 如果均方误差小于临界值\n",
    "        if (node.Nt <= sample_threshold) or (len(Attribute) == 0) or (node.loss < loss_threshold)\\\n",
    "            or (max_depth and deep > max_depth):\n",
    "            node.character = 'leaf'\n",
    "            node.setLabel(node.maxLabel)\n",
    "            # 保存叶节点的指针，用于剪枝\n",
    "            if deep in self.leaf_ptr:\n",
    "                self.leaf_ptr[deep].append(node) \n",
    "            else:\n",
    "                self.leaf_ptr[deep] = [node]\n",
    "            return node\n",
    "        # 计算切分点(s,j)\n",
    "        min_split_feature = None # 待确认的划分特征s\n",
    "        min_split_point = None # 待确认的划分点j\n",
    "        min_score = np.inf # 用于更新最小平方误差和\n",
    "        for A in Attribute: # 遍历每一个特征s\n",
    "            # 如果该特征是类别型变量\n",
    "            min_store = {} # 存储当前特征各分割点的分数\n",
    "            if A in self.category_cols: \n",
    "                values = Data[0][A].unique()\n",
    "            else:\n",
    "                # 求出分割点\n",
    "                if node.Nt > 10: # 样本量较大时，用分位数求\n",
    "                    values = [Data[0][A].quantile(0.1*i) for i in range(1,10)]\n",
    "                else:\n",
    "                    temp = (Data[0][A].sort_values()).values # 样本量较小时，直接求间隔值\n",
    "                    values = [(temp[i]+temp[i+1])/2 for i in range(len(temp)-1)]\n",
    "            # 遍历每一个可能取值，计算平方损失和\n",
    "            # 便利每一种可能的二叉划分，计算平方损失和\n",
    "            for split_point in values:\n",
    "                if A in self.category_cols: \n",
    "                    index_true = Data[0][A] == split_point\n",
    "                    index_false = Data[0][A] != split_point\n",
    "                else:\n",
    "                    index_true = Data[0][A] <= split_point\n",
    "                    index_false = Data[0][A] > split_point\n",
    "                # 计算平方误差和或者Gini指标\n",
    "                min_store[split_point] = 0\n",
    "                if self.task == 'regression':\n",
    "                    if index_true.any():\n",
    "                        min_store[split_point] += self.__MSEloss(Data[1].values[index_true],Data[1].values[index_true].mean())\n",
    "                    if index_false.any():\n",
    "                        min_store[split_point] += self.__MSEloss(Data[1].values[index_false],Data[1].values[index_false].mean())\n",
    "                else:\n",
    "                    if index_true.any():\n",
    "                        min_store[split_point] += (index_true.sum()/node.Nt)*self.__Gini(Data[1][index_true])\n",
    "                    if index_false.any():\n",
    "                        min_store[split_point] += (index_false.sum()/node.Nt)*self.__Gini(Data[1][index_false])\n",
    "            # 在损失中找到最小的分裂点j\n",
    "            min_store = pd.Series(min_store)\n",
    "            min_store = min_store.sort_values()\n",
    "            # 如果找到了损失更小的划分，则更新划分点\n",
    "            if min_store.values[0] < min_score:\n",
    "                min_score = min_store.values[0]\n",
    "                min_split_feature = A\n",
    "                min_split_point = min_store.index[0]\n",
    "        # 记录该节点的分割位置\n",
    "        node.split = min_split_point\n",
    "        node.setLabel(min_split_feature) # 为该店添加特征标签\n",
    "        node.character = 'child node' # 标记该点的类型\n",
    "        node.kind = 'category' if min_split_feature in self.category_cols else 'numerical' # 标记该节点的划分变量类型\n",
    "        # 确定数据集划分的索引\n",
    "        if node.kind == 'category':\n",
    "            index_left = Data[0][min_split_feature] == min_split_point\n",
    "            index_right = Data[0][min_split_feature] != min_split_point\n",
    "        else:\n",
    "            index_left = Data[0][min_split_feature] <= min_split_point\n",
    "            index_right = Data[0][min_split_feature] > min_split_point\n",
    "        # 利用索引划分数据集\n",
    "        Dx_left = Data[0][index_left]\n",
    "        Dx_right = Data[0][index_right]\n",
    "        Dy_left = Data[1][index_left]\n",
    "        Dy_right = Data[1][index_right]\n",
    "        # 递归添加叶节点，注意更新深度\n",
    "        if node.kind == 'category':\n",
    "            # 判断是否需要剔除一些不再需要划分的列\n",
    "            Attribute_left, Attribute_right = Attribute.copy(), Attribute.copy()\n",
    "            Attribute_left.remove(min_split_feature)\n",
    "            if Dx_right[min_split_feature].nunique() == 1:\n",
    "                Attribute_right.remove(min_split_feature)\n",
    "            node.LEFT = self._TreeGeneratorCART((Dx_left,Dy_left), Attribute_left,\\\n",
    "                                                 deep + 1, sample_threshold, loss_threshold, max_depth)\n",
    "            node.RIGHT = self._TreeGeneratorCART((Dx_right,Dy_right), Attribute_right,\\\n",
    "                                                  deep + 1, sample_threshold, loss_threshold, max_depth)\n",
    "        else:\n",
    "            node.LEFT = self._TreeGeneratorCART((Dx_left,Dy_left), Attribute,\\\n",
    "                                                 deep + 1, sample_threshold, loss_threshold, max_depth)\n",
    "            node.RIGHT = self._TreeGeneratorCART((Dx_right,Dy_right), Attribute,\\\n",
    "                                                  deep + 1, sample_threshold, loss_threshold, max_depth)\n",
    "        # 添加父节点信息\n",
    "        node.LEFT.setParent(node)\n",
    "        node.RIGHT.setParent(node)\n",
    "        return node\n",
    "\n",
    "    # 剪枝\n",
    "    def _Pruning(self, alpha : float=1e-4) -> None:\n",
    "        \"\"\"\n",
    "        _Pruning(self, alpha : float=0.01) -> None\n",
    "            对生成好的决策树进行剪枝\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        alpha : float, optional\n",
    "            剪枝时的正则化系数，默认值1e-4\\n\n",
    "            alpha取值越大，模型复杂度越低\n",
    "        \"\"\"\n",
    "        # 计算整棵树的完整熵\n",
    "        for key in self.leaf_ptr.index: # 按深度遍历叶节点\n",
    "            for leaf in self.leaf_ptr[key]: # 遍历所有叶节点的指针\n",
    "                self.treeEntropy += leaf.Nt*leaf.entropy / self.N\n",
    "        self.treeEntropy += alpha*sum([len(leaf) for leaf in self.leaf_ptr]) # 添加上模型复杂度\n",
    "        # 开始循环剪枝，直至子树的熵不再减少\n",
    "        flag = 1 # 判别变量\n",
    "        while flag:\n",
    "            flag = 0\n",
    "            self.leaf_ptr = self.leaf_ptr.sort_index(ascending=False) # 按叶节点深度排序\n",
    "            for depth in self.leaf_ptr.index: # 按深度遍历叶节点\n",
    "                for leaf in self.leaf_ptr[depth]: # 遍历所有叶节点的指针\n",
    "                    newEntropy = self.__newEntropy(leaf,alpha) # 计算叶节点回缩到父节点后新树的熵\n",
    "                    if newEntropy > self.treeEntropy:\n",
    "                        continue\n",
    "                    # 进入到剪枝分支\n",
    "                    else:\n",
    "                        flag = 1 # 改变判别变量，再次循环\n",
    "                        # 创建双边队列，准别遍历树结构删除该父节点下的所有叶\n",
    "                        queue = collections.deque([leaf._parent]) \n",
    "                        while len(queue) > 0:\n",
    "                            child = queue.popleft()\n",
    "                            # 删除叶子并删除叶的指针\n",
    "                            if child.character == 'leaf' and child in self.leaf_ptr[child.depth]:\n",
    "                                self.leaf_ptr[child.depth].remove(child)\n",
    "                                self.num_leaf -= 1 # 更新叶节点数量\n",
    "                            else:\n",
    "                                for c,c_node in child.children.items(): # 广度优先，添加其它叶子\n",
    "                                    queue.append(c_node)\n",
    "                        # 更新父节点的子节点信息\n",
    "                        leaf._parent.children = {}\n",
    "                        # 将父节点设置为叶节点\n",
    "                        leaf._parent.character = 'leaf'\n",
    "                        leaf._parent.setLabel(leaf._parent.maxLabel)\n",
    "                        # 更新叶节点数量\n",
    "                        self.num_leaf += 1\n",
    "                        # 将新的叶节点的指针保存\n",
    "                        if depth-1 in self.leaf_ptr.index:\n",
    "                            self.leaf_ptr[depth-1].append(leaf._parent)\n",
    "                        else:\n",
    "                            self.leaf_ptr[depth-1] = [leaf._parent]\n",
    "                        # 更新树的熵\n",
    "                        del leaf\n",
    "                        self.treeEntropy = newEntropy\n",
    "                        break # 每次更新跳出当前循环，从头开始剪枝\n",
    "                # 如果判别指标为真，直接跳出深度遍历，从头开始遍历整个树的叶\n",
    "                if flag == 1:\n",
    "                    break\n",
    "    \n",
    "    # CART剪枝\n",
    "    def _PruningCART(self, valid_data : tuple=None, greater_is_better : bool=True) -> None:\n",
    "        \"\"\"\n",
    "        _PruningCART(self) -> None\n",
    "            对生成好的CART决策树进行剪枝\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        valid_data : tuple\n",
    "            剪枝时所需的验证数据集，它应该和训练数据集独立\\n\n",
    "            valid_data的形式为(X_valid,y_valid)的元组\\n\n",
    "        greater_is_better : bool, optional\n",
    "            在进行交叉验证选择最优子树时，确定决策分数是越高越好(例如正确率)还是越低越好(例如平方误差)\\n\n",
    "            默认值为True\n",
    "        \"\"\"\n",
    "        # 计算以每个子节点为根节点剪枝临界值alpha\n",
    "        # 广度有限搜索\n",
    "        queue = collections.deque([self.tree])\n",
    "        while len(queue) > 0:\n",
    "            child = queue.popleft()\n",
    "            # 如果不是叶节点，就计算剪枝临界值\n",
    "            if child.character != 'leaf':\n",
    "                self.__computeAlpha(child)\n",
    "                # 为该临界值添加指向该根节点的指针\n",
    "                self.alphaTree[child.alpha] = child\n",
    "                if child.LEFT.character != 'leaf':\n",
    "                    queue.append(child.LEFT)\n",
    "                if child.RIGHT.character != 'leaf':\n",
    "                    queue.append(child.RIGHT)\n",
    "        self.alphaTree = pd.Series(self.alphaTree)\n",
    "        # 排序\n",
    "        self.alphaTree = self.alphaTree.sort_index(ascending=True)\n",
    "        # 保存原始的完整树\n",
    "        self.pruningTree[0] = self.__copyTreeCART(self.tree)\n",
    "        # # 开始剪枝\n",
    "        for alpha in self.alphaTree.index:\n",
    "            # 剪掉alpha对应的节点\n",
    "            node = self.alphaTree[alpha]\n",
    "            # 节点回退\n",
    "            node.LEFT = None\n",
    "            node.RIGHT = None\n",
    "            # 将父节点设置为叶节点\n",
    "            node.character = 'leaf'\n",
    "            node.setLabel(node.maxLabel)\n",
    "            # 复制这棵树\n",
    "            self.pruningTree[alpha] = self.__copyTreeCART(self.tree)\n",
    "        if greater_is_better:\n",
    "            best_score = -np.inf\n",
    "        else:\n",
    "            best_score = np.inf\n",
    "        # 选择最好的树\n",
    "        for alpha,tree in self.pruningTree.items():\n",
    "            self.tree = tree\n",
    "            score = self.accuracy(valid_data[0],valid_data[1])\n",
    "            if greater_is_better:\n",
    "                if score > best_score:\n",
    "                    best_score = score\n",
    "                    best_alpha = alpha\n",
    "            else:\n",
    "                if score < best_score:\n",
    "                    best_score = score\n",
    "                    best_alpha = alpha\n",
    "        # 保存最好的树\n",
    "        self.tree = self.pruningTree[best_alpha]\n",
    "                    \n",
    "    def __entropy(self, X : pd.Series) -> float:\n",
    "        \"\"\"\n",
    "        信息熵计算函数\n",
    "        \"\"\"\n",
    "        p = X.value_counts() / len(X)\n",
    "        return -(p*np.log2(p)).sum()\n",
    "\n",
    "    def __relative_entropy(self, X : pd.Series, Y : pd.Series) -> float:\n",
    "        \"\"\"\n",
    "        相对熵计算函数\n",
    "        \"\"\"\n",
    "        H = 0\n",
    "        for x in X.unique():\n",
    "            nx = (X==x).sum()\n",
    "            h = 0\n",
    "            for y in Y.unique():\n",
    "                if ((X==x) & (Y==y)).any():\n",
    "                    h += ((X==x) & (Y==y)).sum() / nx\n",
    "                else:\n",
    "                    h += 0\n",
    "            H += -h * nx / len(X)\n",
    "        return H\n",
    "\n",
    "    def __mutaul_information(self, X : pd.Series, Y : pd.Series) -> float:\n",
    "        \"\"\"\n",
    "        互信息量计算函数\n",
    "        \"\"\"\n",
    "        return self.__entropy(X) - self.__relative_entropy(X,Y)\n",
    "    \n",
    "    def __empiricalEntropy(self, Ntk : pd.Series) -> float:\n",
    "        \"\"\"\n",
    "        各叶子节点的经验熵计算函数\n",
    "        \"\"\"\n",
    "        p = Ntk / Ntk.sum()\n",
    "        return -(p*np.log(p)).sum()\n",
    "    \n",
    "    def __MSEloss(self, y : pd.Series, label : float) -> float:\n",
    "        \"\"\"\n",
    "        计算均方损失\n",
    "        \"\"\"\n",
    "        return ((y - label)**2).sum()\n",
    "    \n",
    "    def __Gini(self, y : pd.Series) -> float:\n",
    "        \"\"\"\n",
    "        计算Gini指数\n",
    "        \"\"\"\n",
    "        p = y.value_counts() / len(y)\n",
    "        return 1 - (p**2).sum()\n",
    "    \n",
    "    def __newEntropy(self, node : 'Node', alpha : float) -> float:\n",
    "        \"\"\"\n",
    "        __newEntropy(self, node : 'Node', alpha : float) -> float\n",
    "            剪枝时，计算叶节点回缩到父节点后，新树的熵\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        node : Node\n",
    "            要进行剪切的叶节点\n",
    "        alpha : float\n",
    "            剪枝算法的正则化参数\n",
    "        \n",
    "        Return\n",
    "        ----------\n",
    "        entropy : float\n",
    "            叶节点回缩到父节点后，新树的熵\n",
    "        \"\"\"\n",
    "        entropy = self.treeEntropy # 在原有熵的基础上更新\n",
    "        try:\n",
    "            # 创建双边队列，使用广度优先寻找每一个叶节点\n",
    "            queue = collections.deque([node._parent])\n",
    "            while len(queue) > 0:\n",
    "                child = queue.popleft()\n",
    "                # 减去该叶节点，熵的变化量\n",
    "                if child.character == 'leaf':\n",
    "                    entropy -= (child.Nt*child.entropy/self.N+alpha)\n",
    "                else:\n",
    "                    for c,c_node in child.children.items(): # 添加其它叶节点\n",
    "                        queue.append(c_node)\n",
    "            # 所有叶节点删除后，添加上最新父节点的熵和对应的复杂度\n",
    "            entropy += node._parent.Nt*node._parent.entropy/self.N\n",
    "            entropy += alpha\n",
    "            return entropy\n",
    "        except AttributeError:\n",
    "            return entropy + 1\n",
    "    \n",
    "    # 计算CART决策树的剪枝临界值\n",
    "    def __computeAlpha(self, node : 'Node') -> None:\n",
    "        \"\"\"\n",
    "        __computeAlpha(self, node : 'Node') -> None\n",
    "            CART剪枝时，计算各子节点的剪枝临界值alpha，并保存到各个节点\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        node : Node\n",
    "            决策树中的子节点\n",
    "        \"\"\"\n",
    "        # 该node为根下的叶节点数量\n",
    "        T = 0\n",
    "        # 该node为根下的叶节点带来的损失\n",
    "        root_loss = 0\n",
    "        # 创建双边队列，使用广度优先搜索寻找每一个叶节点\n",
    "        queue = collections.deque([node])\n",
    "        while len(queue) > 0:\n",
    "            child = queue.popleft()\n",
    "            # 如果是叶节点，计算以node为根节点的树的损失\n",
    "            if child.character == 'leaf':\n",
    "                root_loss += (child.Nt/self.N)*child.loss\n",
    "                T += 1\n",
    "            # 添加节点\n",
    "            else:\n",
    "                if child.LEFT:\n",
    "                    queue.append(child.LEFT)\n",
    "                if child.RIGHT:\n",
    "                    queue.append(child.RIGHT)\n",
    "        # 记录下alpha的值\n",
    "        node.alpha = (node.loss*node.Nt/self.N - root_loss) / (T - 1)\n",
    "    \n",
    "    # 复制一棵树\n",
    "    def __copyTreeCART(self, node : 'Node') -> 'Node':\n",
    "        \"\"\"\n",
    "        __copyTreeCART(self, node : 'Node') -> 'Node'\n",
    "            CART剪枝时，对各个剪枝后的子树进行拷贝复制\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        node : Node\n",
    "            CART剪枝过程中子树的头节点\n",
    "        \"\"\"\n",
    "        # 创建新节点，复制节点信息\n",
    "        copy_node = Node('CART')\n",
    "        copy_node.character = node.character # 该节点的属性\n",
    "        copy_node.split = node.split # 该节点的最佳分裂点\n",
    "        copy_node._label = node._label # 该节点的标签\n",
    "        copy_node.Nt = node.Nt # 该节点所包含的样本量\n",
    "        copy_node.depth = node.depth # 该节点所处的树深度\n",
    "        copy_node.loss = node.loss # 该节点的平方损失和\n",
    "        copy_node.Gini = node.Gini # 该节点的Gini指数\n",
    "        copy_node.kind = node.kind # 该节点是类别型还是数值型\n",
    "        copy_node.alpha = node.alpha # 决定是否剪枝的临界值\n",
    "        # 如果没有复制到叶节点，则递归地复制左右节点\n",
    "        if copy_node.character != 'leaf':\n",
    "            copy_node.LEFT = self.__copyTreeCART(node.LEFT)\n",
    "            copy_node.RIGHT = self.__copyTreeCART(node.RIGHT)\n",
    "            # 设置节点的父亲\n",
    "            copy_node.LEFT.setParent(copy_node)\n",
    "            copy_node.RIGHT.setParent(copy_node)\n",
    "        return copy_node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model,task : str='regression'):\n",
    "    if task == 'regression':\n",
    "        print(\"train: \")\n",
    "        print(\"mean square error: \",model.accuracy(train_data[features],train_data[label],'MSE'))\n",
    "        print(\"maximum absolute error: \",model.accuracy(train_data[features],train_data[label],'MAE'))\n",
    "        print(\"mean absolute error: \",model.accuracy(train_data[features],train_data[label],'mean absolute error'))\n",
    "        print(\"test: \")\n",
    "        print(\"mean square error: \",model.accuracy(test_data[features],test_data[label],'MSE'))\n",
    "        print(\"maximum absolute error: \",model.accuracy(test_data[features],test_data[label],'MAE'))\n",
    "        print(\"mean absolute error: \",model.accuracy(test_data[features],test_data[label],'mean absolute error'))\n",
    "    if task == 'classification':\n",
    "        print(\"train: \")\n",
    "        print(\"acc: \",model.accuracy(train_data[features],train_data[label]))\n",
    "        print(\"test: \")\n",
    "        print(\"acc: \",model.accuracy(test_data[features],test_data[label]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 随机森林"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomForest(DecisionTree):\n",
    "    \"\"\"\n",
    "    class RandomForest(DecisionTree):\n",
    "    |  随机森林模型\n",
    "    |  继承自决策树，通过调用多棵决策树，使用投票或平均的方法实现分类和回归\n",
    "    |\n",
    "    |  Parameters\n",
    "    |  ----------\n",
    "    |  task : str, optional\n",
    "    |      任务类型，取值['regression','classification']\\n\n",
    "    |      默认值'classification'\n",
    "    |  n_estimators : int, optional\n",
    "    |      所使用的分类器个数，默认值10\n",
    "    |  max_feature_split : int, optional\n",
    "    |      训练单棵决策树时的最大分类特征数量\n",
    "    |      默认值None，表示使用所有特征\n",
    "    |  max_depth : int, optional\n",
    "    |      训练单棵决策树时的最大树深度\n",
    "    |      默认值None，表示不限制树的深度\n",
    "    |  min_sample_leaf : int, optional\n",
    "    |      训练单棵决策树时的叶子节点的最小样本数量\n",
    "    |      默认值1\n",
    "    |\n",
    "    |  Atrribute\n",
    "    |  ----------\n",
    "    |  __init__(self, task : str='classification', n_estimators : int=10, \n",
    "    |           max_feature_split : int=None, max_depth : int=None, min_sample_leaf : int=1) -> None\n",
    "    |      初始化函数\n",
    "    |  fit(self, X : pd.DataFrame, y : pd.Series, numerical_cols : list=None) -> None\n",
    "    |      训练函数\n",
    "    |  predict(self, X : pd.DataFrame)\n",
    "    |      预测函数\n",
    "    |  accuracy(self, X : pd.DataFrame, y_true : pd.Series) -> float\n",
    "    |      正确率计算函数\n",
    "    |  \n",
    "    |  以及其它从父类DecisionTree继承得到的方法\n",
    "    |\n",
    "    \"\"\"\n",
    "    def __init__(self, task : str='classification', n_estimators : int=10, \n",
    "                max_feature_split : int=None, max_depth : int=None, min_sample_leaf : int=1) -> None:\n",
    "        \"\"\"\n",
    "        __init__(self, task : str='classification', n_estimators : int=10, \n",
    "                max_feature_split : int=None, max_depth : int=None, min_sample_leaf : int=1) -> None\n",
    "            类构造初始化函数，见类使用说明\n",
    "        \"\"\"\n",
    "        self.task = task\n",
    "        self.n_estimators = n_estimators\n",
    "        self.max_feature_split = max_feature_split\n",
    "        self.max_depth = max_depth\n",
    "        self.min_sample_leaf = min_sample_leaf\n",
    "        self.oof_scores = None # 包外估计分数\n",
    "        self.model_list = []\n",
    "        self.feature_importance = {} # 特征重要性\n",
    "    \n",
    "    def fit(self, X : pd.DataFrame, y : pd.Series, numerical_cols : list=None) -> None:\n",
    "        \"\"\"\n",
    "        fit(self, X : pd.DataFrame, y : pd.Series, numerical_cols) -> None\n",
    "            输入训练数据集，训练生成随机森林\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        X : pd.DataFrame\n",
    "            数据的特征\n",
    "        y : pd.Series\n",
    "            数据的标签\n",
    "         numerical_cols : list, optional\n",
    "            数据集中数值型变量的列名\n",
    "        \"\"\"\n",
    "        model_list = []\n",
    "        oof_scores = 0\n",
    "        # 初始化特征重要性\n",
    "        for col in X.columns:\n",
    "            self.feature_importance[col] = 0\n",
    "        for i in range(self.n_estimators):\n",
    "            X_train, X_valid, y_train, y_valid = train_test_split(X,y,test_size=0.3)\n",
    "            X_train = X_train.reset_index(drop=True)\n",
    "            y_train = y_train.reset_index(drop=True)\n",
    "            X_valid = X_valid.reset_index(drop=True)\n",
    "            y_valid = y_valid.reset_index(drop=True)\n",
    "            DTmodel = DecisionTree(task=self.task,method='CART')\n",
    "            DTmodel.fit(X_train,y_train,numerical_cols=numerical_cols,\n",
    "                        is_pruning=False,sample_threshold=self.min_sample_leaf,loss_threshold=0.1,\n",
    "                        max_feature_split=self.max_feature_split,max_depth=self.max_depth)\n",
    "            model_list.append(DTmodel)\n",
    "            # 计算包外估计分数\n",
    "            oof_scores += DTmodel.accuracy(X_valid,y_valid) / self.n_estimators\n",
    "            # 通过特征置换，计算重要性\n",
    "            for k,v in self.feature_importance.items():\n",
    "                temp = X_valid.copy()\n",
    "                temp.loc[:,k] = temp.loc[:,k].sample(frac=1).values\n",
    "                change_score = DTmodel.accuracy(X_valid,y_valid) - DTmodel.accuracy(temp,y_valid)\n",
    "                self.feature_importance[k] += change_score / self.n_estimators \n",
    "        self.feature_importance = pd.Series(self.feature_importance)\n",
    "        self.feature_importance = self.feature_importance - self.feature_importance.values.min()\n",
    "        self.oof_scores = oof_scores\n",
    "        self.model_list = model_list\n",
    "    \n",
    "    def predict(self, X : pd.DataFrame) -> pd.Series:\n",
    "        \"\"\"\n",
    "        predict(self, X : pd.DataFrame) -> pd.Series\n",
    "            输入数据，进行预测\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        X : pd.DataFrame\n",
    "            数据的特征\n",
    "\n",
    "        Return\n",
    "        ----------\n",
    "        y_pred : pd.Series\n",
    "            模型在输入X上的预测\n",
    "        \"\"\"\n",
    "        pred_data = pd.DataFrame(data=None)\n",
    "        for i,model in enumerate(self.model_list):\n",
    "            pred_data.loc[:,'model_'+str(i+1)] = model.predict(X)\n",
    "        y_pred = []\n",
    "        for i in range(pred_data.shape[0]):\n",
    "            # 分类任务用投票机制\n",
    "            if self.task == 'classification':\n",
    "                y_pred.append(pred_data.iloc[i,:].mode()[0])\n",
    "            # 回归任务取均值\n",
    "            else:\n",
    "                y_pred.append(pred_data.iloc[i,:].mean())\n",
    "        return pd.Series(y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 分类效果测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_features = ['Attrition_Flag','Gender', 'Dependent_count','Education_Level', \n",
    "                    'Marital_Status', 'Income_Category', 'Card_Category','Total_Relationship_Count', \n",
    "                    'Months_Inactive_12_mon','Contacts_Count_12_mon']\n",
    "numerical_features = ['Customer_Age', 'Months_on_book', 'Credit_Limit', 'Total_Revolving_Bal',\n",
    "                       'Avg_Open_To_Buy', 'Total_Amt_Chng_Q4_Q1', 'Total_Trans_Amt', 'Total_Trans_Ct', \n",
    "                       'Total_Ct_Chng_Q4_Q1', 'Avg_Utilization_Ratio' ]\n",
    "label = 'Attrition_Flag'\n",
    "category_features.remove(label)\n",
    "features = category_features + numerical_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForest(task='classification',n_estimators=5)\n",
    "model.fit(train_data[features],train_data[label],numerical_cols=numerical_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 包外估计分数和测试集正确率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "包外估计的准确率： 0.917142857142857\n",
      "测试集准确率： 0.940837863767189\n"
     ]
    }
   ],
   "source": [
    "print(\"包外估计的准确率：\",model.oof_scores)\n",
    "print(\"测试集准确率：\",model.accuracy(test_data[features],test_data[label]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: \n",
      "acc:  0.9642857142857143\n",
      "test: \n",
      "acc:  0.940837863767189\n"
     ]
    }
   ],
   "source": [
    "evaluate(model,task='classification')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 基于置换的特征重要性"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "PFI = model.feature_importance\n",
    "PFI = PFI.sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BarContainer object of 19 artists>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure(figsize=(8,6))\n",
    "plt.barh(PFI.index,PFI.values,color='royalblue')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "6470f2147c2b739e48a69acfdaab591c02f2a6e83a181052e33caef4d986b070"
  },
  "kernelspec": {
   "display_name": "ML[Python3.9]",
   "language": "python",
   "name": "ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
